%&cheri_misidioms_preamble
\endofdump

\begin{document}
\maketitle

\section{Introduction}

CHERI provides and enforces hardware capabilities that allow programmers to
make strong security guarantees about their programs. Our experience of CHERI
hardware implementations is that the security features they provide are well
thought through and robust -- but the programmer then has to work out how to
use those features to achieve a desired level of security in software.

We have made many mistakes in trying to write software that matches our
security expectations -- indeed, we have made many mistakes in working out what
reasonable security expectations with CHERI might be.  One of the root causes
of our mistakes is that no single source of
documentation systematically covers the subtle implications of CHERI's design.
Put another way, there is currently little documentation explaining `good'
CHERI programming idioms or, as we've come to realise, of `bad' CHERI
programming idioms either.

In this short paper, we capture some `bad' CHERI programming idioms, showing
how these undermine what might have seemed like reasonable security expectations. For
each, we attempt to name the idiom, explain the relevant CHERI features, and
give simple example code. We do not claim that all, or perhaps even any, of the
idioms in this paper are novel, and some may strike seasoned CHERI programmers
as naive --- but we also show how some are present in CheriBSD.
We hope that by capturing several of these idioms in a single place,
naming and describing them, we will make it easier for programmers and
researchers to understand and communicate about both these bad idioms and
those yet to be discovered.


\section{Background}

We assume high-level familiarity with capabilities (an approachable historical overview
is~\cite{levy84capability}, which may usefully be augmented by more recent work
such as \cite{miller06robust}),
CHERI generally (see e.g.~this introduction~\cite{watson20cheriintroduction}),
the CHERI ABI~\cite{brooks19cheriabi},
and CHERI C (the dialect of C that CHERI defines)~\cite{watson20chericprogramming}.

Because CHERI has been developed over a number of years, and is explained over
a variety of documentation and papers, some concepts have more than one name.
We have found that some of those names make it difficult to talk, and sometimes
reason about, capability usage.
Unfortunately, we can think of no better solution to this than to propose our
own terminology.

We use the term \textit{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI, and a user-facing library that exposes CHERI-related
functions. We refer to specific hardware implementations by their name
(e.g.~Arm's `Morello', or `CHERI RISC-V'). CHERI provides two modes of
operation: \textit{hybrid} execution, where `traditional' pointers can be
freely mixed alongside (`fat pointer') `capabilities'; and \textit{pure
capability} execution where only capabilities can be used.

CHERI capabilities are immutable and thus a new \emph{child}
capability must be derived from one or more \emph{parent} capabilities.
We refer to a capability as \emph{authentic} (what CHERI calls
`tagged' or `valid') if it has been derived from its parents according
to CHERI's rules, or \emph{inauthentic} (what CHERI calls `untagged' or `invalid')
otherwise. A capability consists of an \emph{address} in memory
and a set of \emph{permissions}. Amongst the permissions are
\emph{bounds} -- the region of memory an authentic capability is allowed to
read/write from/to. A capability's bounds are from a \emph{low} (inclusive) to
a \emph{high} (exclusive) address and we refer to `a bound of $x$ bytes' to mean
a capability where $\textit{high}-\textit{low}=x$.
If a capability's address is contained within its bounds we refer to the capability as
a whole as \emph{in-bounds} or \emph{out-of-bounds} otherwise
(see~\cite{woodruff19chericoncentrate} for an explanation of why an authentic
capability might have an out-of-bounds address). Other permissions include
boolean flags such as whether a capability can read/write to memory addresses
within its bounds.


\section{\privesc: Privilege Escalation}

The most dangerous attacks on any capability system are those where an attacker
is able to unexpectedly elevate a capability's privileges. Formally speaking, CHERI capabilities
have monotonically decreasing privileges: in other words, when taking an existing
capability \emph{C1} as input, any capability \emph{C2} we derive from
\emph{C1} must have the same or fewer privileges. This may seem to make it
impossible to increase a capability's privileges, but software
components can store high privilege capabilities that can then be used to
give the appearance of returning a capability with increased privileges.

Functions which take in a low privileged capability and use a
higher\footnote{More formally, a capability with disjoint privileges to the
input capability} privileged capability to perform calculations are at risk of
privilege escalation, and need to be carefully audited for bad idioms.


\subsection{Insufficient validation of the input capability}

Consider a memory allocator whose \texttt{realloc(cap, size)} function takes in
a capability \texttt{cap} whose address references the beginning of a block of
memory and returns a new capability whose address references the beginning of a
block of memory sufficient for storing \texttt{size} bytes.
A common \texttt{realloc} optimisation is to avoid moving memory if the
requested size fits within the `bucket' that the block already resides within.
We might then write a simple \texttt{realloc} as follows, assuming that we have
access to a high-privileged capability \texttt{MC} (e.g.~from
\texttt{mmap}~\cite{brooks19cheriabi}):

\begin{lstlisting}[language=C]
void *realloc(void *cap, size_of size) {
  if (size_of_bucket(cap) <= size) {
    // No need to reallocate.
    return cheri_bounds_set(
      cheri_address_set(MC, cap),
      size);
  } else {
    // Allocate a larger region of memory and copy
    // cap's contents over.
    ...
  }
}
\end{lstlisting}

\noindent The crucial optimisation is on line 2: if we already have enough
memory for the resized block, we simply return a new capability with the same
address as the original capability but with an upper bound \texttt{size}. By definition, reducing
the size of a block means that it will always fit within its existing bucket so
the above optimisation is guaranteed to be correct.

Unfortunately this implementation of \texttt{realloc} is subject to privilege
escalation. For example, one can pass in a capability with narrow bounds and
receive back a capability with wider bounds:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
arr = cheri_bounds_set(arr, 8);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 8);
arr = realloc(arr, 16);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 16);
\end{lstlisting}

We first \texttt{malloc} a block, returning a capability \emph{C1} with bounds
$0\ldots{}n$ bytes (line 1). We then derive a new capability \emph{C2} with
bounds $0\ldots{}m$ bytes where $m < n$ (lines 2 and 3). We can then use
\texttt{realloc} to turn \emph{C2} back into \emph{C1} -- even though we had
lost access to \emph{C1} entirely!

This is not just a theoretical attack: our example \texttt{realloc} is effectively
a simplified version of CheriBSD's \texttt{realloc}, which (as of
2021-08-18\footnote{\href{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}})
is vulnerable to this attack. Any capability whose bounds contain the base address of
a memory block can potentially have its privileges escalated, with
\texttt{realloc} returning a capability with the same permissions as the memory
system's main capability (as well as widening bounds, this allows
e.g.~upgrading a read-only capability to a read/write capability).


\subsection{Mitigations}

Privilege escalation occurs when a function fails to fully validate a possibly
lower-privileged capability correctly before using a higher-privileged
capability. Exactly what validation should occur is highly situation dependent,
which is why it is easy to get wrong.

In most, perhaps all, reasonable cases, the input CHERI capability should be
authentic and the capability's address in-bounds. However, as our
\texttt{realloc} attack shows, these two conditions are necessary but not
sufficient.  For example, one solution to the \texttt{realloc} attack is to
check that \texttt{cap}'s address refers to the start of a memory block and
that the capability's permissions are equal to the permissions returned by the
most recent \texttt{malloc} or \texttt{realloc} for that memory block. This
implies that the memory allocator must either store, or be able to derive by
other means, the capability returned by the most recent \texttt{malloc} or
\texttt{realloc} call.

However, it may be too restrictive to restrict \texttt{realloc} to precisely
equal capabilities: one may wish to allow \emph{compatible} capabilities. The
definition of compatibility is then crucial, particularly as different CHERI
architectures have different bounds representations and permissions.


\section{\narrowingdoesnt: Narrowing a capability's bounds does not always fully narrow the capability's bounds}

Capabilities have high and low bounds, which are a strong enforcement mechanism
for restricting the region of memory that the capability can access for
reading and writing.
It is thus tempting to write code which hides secrets beyond the reach of a
capability's bounds such as the following:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *array_with_hidden_secret(size_t size) {
    uint8_t *arr = malloc(size);
    return cheri_bounds_set(arr, size - 1);
}
\end{lstlisting}

\noindent We first \texttt{malloc} an array big enough space to store
\texttt{size} many \texttt{u8}s (line 2) before creating a child capability
which prevents access to the array's final byte (line 3). We can verify this
behaviour by checking the returned capability's length, as in the following
code, which executes without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16385);
assert(cheri_length_get(arr) == 16384);
\end{lstlisting}

However, this idiom is insidious because it works correctly for the sorts of
`human friendly' sizes that programmers tend to test, but not for many other
sizes. As we saw above, creating a capability with a bound of 16384 bytes
prevents access to the array's last byte. However, making the array 1 byte
bigger undermines our expectations, as in the following code, which executes
without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16386);
assert(cheri_length_get(arr) == 16392);
\end{lstlisting}

Note that though we expected a capability with a bound of 16385 bytes, instead
the length is 16392 bytes. On Morello, 16385 bytes is the smallest bound which
can not be precisely represented in a capability, and thus it has been been
rounded up to the next representable bound. If we rely on capability bounds to
prevent access to secrets, as in our example above, this can cause secrets to
leak.

Practically speaking, this means that one cannot expect that narrowing a
capability's bounds precisely captures only the requested region of memory: in
general, the capability will provide access to more memory than one wishes.
Forgetting to take account of this, as in our example above, leads to secrets
being leaked. \laurie{mention cheri\_bounds\_set\_exact}

\jacob{Notably, occurrences of this pattern in real code will (as we've seen) be
much less obvious, and very hard to spot in code reviews. We could really do
with a helper that tests whether or not a hypothetical access would be
permitted, so we can write assertions in our \texttt{realloc} implementation, etc.}

The underlying issue is that modern CHERI systems use `CHERI
Concentrate'~\cite{woodruff19chericoncentrate}, an approach to representing
bounds that requires relatively few bits: for example Morello's capabilities
have 31 bits to express the bounds for a 64-bit address space. The trade-off is
simple: the fewer bits used for bounds the smaller capabilities are (which is
good for memory use and performance), but the less precise the bounds that can
be represented. The encoding is ingenious, but hard to capture succinctly: in essence,
bounds use exponents, in similar fashion to IEEE 754 floating point
numbers: the wider the bound, the less accurately it will be
represented. When a desired length cannot be precisely represented, the next
largest precisely representable length is used in the bound. On Morello, for
example, small bounds up to, but excluding, 16385 bytes are precisely
represented, but if one tries to create a bound of 16385 bytes, it
is rounded up to 16392 bytes.


\subsection{Mitigations}

There are two approaches that can ensure that narrowing bounds does not cause
secrets to be leaked.

First, one can check whether the narrowed bounds do/would capture only the
desired region of memory and if they don't/wouldn't, move the secret data to a
(probably new) non-overlapping region of memory. One can check whether bounds
will be adequately narrowed in advance using
\texttt{cheri\_representable\_length} or retrospectively by querying the
narrowed capability with \texttt{cheri\_length\_get}.

Second, one can lay out memory in advance such that, no matter what
imprecise bounds are used, secrets will not leak. In essence, this requires
adding padding to each object to take account of imprecise bounds. One could rewrite
\texttt{array\_with\_hidden\_secret} using this technique, provided that the
number of secret items at the end of the array does not vary after array creation
time.

These two approaches have different costs. The first approach requires users
only to pay for the cost of wasted memory if it is needed. However, at best
this introduces unexpected pauses as memory is allocated and copied. At worst,
this approach is infeasible --- one cannot, for example, easily move the
\emph{n}th element of a contiguous array because it is too big to be
represented with precise bounds. The second approach, in contrast, has fixed
up-front costs, but requires wasting memory for every object, even if no
future capability will ever have bounds covering it.

\jacob{The first mental response I had was to wonder why we're trying to
allocate non-secret and secret memory together anyway. There are good reasons
(e.g. discoverability for allocation metadata), but also, this is exactly the
problem I had when prototyping the stack compartmentalisation idea, and bump
pointer allocators hit this for every allocation. I'm not sure if we need to
reinforce this with a practical example, but they certainly exist.}
\laurie{i'm trying to think of a non-artifical example... any suggestions?}


\section{\narrowwiden: Narrowing then widening}

Assuming that a child capability with narrow bounds has been derived while
respecting the issues raised in \narrowingdoesnt, it may seem that our issues
with capability bounds are over. However, if one later widens those bounds
again, one may unintentionally leak secrets.

CheriBSD's default \texttt{realloc} is subject to this problem. The following
code executes successfully, with the capability returned by \texttt{realloc}
giving access to the same range of memory as the original \texttt{malloc}. Note
that \texttt{realloc} does not move, or scrub, memory in such a case. Thus, if
the user expected the setting of bounds to protect a secret, this code will not
give the protection expected.

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++) arr[i] = i;
arr = realloc(arr, 1);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++) assert(arr[i] == i);
\end{lstlisting}


\subsection{Mitigations}

In the specific example above, \texttt{realloc} should scrub memory when the
size of a memory block is being narrowed. However, this may not be appropriate
in all cases, particularly where capability bounds narrowing is being used to
hide a secret from another compartment. In such cases, code which can widen a
capability's bounds must be carefully audited.


\section{\undef: Authentic capabilities from undefined behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's rules correctly. However, it is possible for an attacker to
use undefined behaviour to derive authentic capabilities. Consider the
following code:

\begin{lstlisting}[language=C]
uint8_t *c1 = malloc(16);
vaddr_t c1_addr = cheri_address_get(c1);
uint8_t *c2 = cheri_bounds_set(c1, 8);

free(c2);
uint8_t *c3 = malloc(16);
assert(cheri_tag_get(c3) && cheri_length_get(c3) == 16);
assert(cheri_address_get(c3) == c1_addr);
\end{lstlisting}

In this example, we first derive a capability \emph{C1} with bounds of 16 bytes
(line 1) before deriving a narrower capability \emph{C2} from it (line 3). It
is then possible that after \texttt{free}ing the block of memory addressed by \emph{C1},
a subsequent \texttt{malloc} of 16 bytes returns a
capability \emph{C3} that is identical to \emph{C1}. This attack relies
on the underlying memory allocator reusing memory blocks, which many do in a
predictable fashion: this example runs successfully on CheriBSD (as of
2021-08-19).

Interestingly, C's pointer provenance rules mean that, after the code above has
executed, using \emph{C1} is no longer defined behaviour though this will not
trouble an attacker, who will find that most programs still execute as expected
and who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsection{Mitigations}

There are no general mitigations for \undef. For the particular concrete
example, a partial mitigation is for \texttt{free} to scrub memory so that, at
least, whatever was present in the buffer cannot read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \texttt{free} to
revoke all references to the capability. In other words, CHERI allows one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and invalidate the capability~\cite{xia19cherivoke}. In this case, this
means that the original code will then fail with a \texttt{SIGPROT} when it
tries to use \emph{C1}, downgrading the security leak into a denial-of-service.
However, scanning the stack and heap in order to perform revocation is not
likely to be a quick operation.


\section{Protecting the whole but not the parts}

\laurie{i.e.~set permissions on a struct attributes but not the struct (or vice versa): capabilities only cover contiguous chunks of memory}


\section{Capability overflow}

\laurie{is this possible?}
\jacob{Not when used in the obvious way (e.g. dereferencing), but extreme
(65-bit) bounds behave in non-portable ways when queried explicitly, e.g.
saturating on Morello, and this isn't obvious in the CHERI API. This makes
manually testing the bounds difficult.}
\laurie{interesting! can we make a simple code example which shows this?}



%\section{Missing or flawed parts of the CHERI API}

%\subsection{\texttt{cheri\_address\_set}}

%\laurie{'cheri_setaddress()` doesn't abort if the result isn't encodable.}


\section{Conclusions}

\textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
comments.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
